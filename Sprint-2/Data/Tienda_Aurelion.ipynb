{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e216fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fase 1: Datos cargados exitosamente.\n",
      "\n",
      "--- Reporte r√°pido de valores nulos ---\n",
      "Clientes: Sin nulos\n",
      "Detalle: Sin nulos\n",
      "Productos: Sin nulos\n",
      "Ventas: Sin nulos\n",
      "‚úÖ Fase 2 completada. Dimensiones del Dataset Maestro: (343, 18)\n",
      "\n",
      "üìä Iniciando an√°lisis de productos...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'nombre_producto'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 191\u001b[39m\n\u001b[32m    188\u001b[39m     analizar_mejores_clientes(df_maestro)\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[38;5;66;03m# ...existing code...\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 186\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    183\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    185\u001b[39m df_maestro = crear_dataset_maestro(df_ventas, df_detalle, df_productos, df_clientes)\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m \u001b[43manalizar_productos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_maestro\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    187\u001b[39m analizar_tendencia_temporal(df_maestro)\n\u001b[32m    188\u001b[39m analizar_mejores_clientes(df_maestro)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 106\u001b[39m, in \u001b[36manalizar_productos\u001b[39m\u001b[34m(df, top_n)\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[33;03mTarea 3: An√°lisis de productos.\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[33;03mMuestra top por cantidad y por importe y dibuja gr√°ficos si est√°n disponibles.\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    105\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müìä Iniciando an√°lisis de productos...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m prod_stats = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnombre_producto\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m.agg({\u001b[33m'\u001b[39m\u001b[33mcantidad\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33msum\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mimporte\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33msum\u001b[39m\u001b[33m'\u001b[39m})\n\u001b[32m    107\u001b[39m top_cant = prod_stats.sort_values(\u001b[33m'\u001b[39m\u001b[33mcantidad\u001b[39m\u001b[33m'\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m).head(top_n)\n\u001b[32m    108\u001b[39m top_ing = prod_stats.sort_values(\u001b[33m'\u001b[39m\u001b[33mimporte\u001b[39m\u001b[33m'\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m).head(top_n)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Miguel\\Desktop\\Miguelon\\GH\\Formacion_IA_DataScience_ML\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:9210\u001b[39m, in \u001b[36mDataFrame.groupby\u001b[39m\u001b[34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   9207\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   9208\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou have to supply one of \u001b[39m\u001b[33m'\u001b[39m\u001b[33mby\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlevel\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m9210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   9211\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   9212\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9213\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9214\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9215\u001b[39m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9216\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9217\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9218\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9219\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9220\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Miguel\\Desktop\\Miguelon\\GH\\Formacion_IA_DataScience_ML\\.venv\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1331\u001b[39m, in \u001b[36mGroupBy.__init__\u001b[39m\u001b[34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   1328\u001b[39m \u001b[38;5;28mself\u001b[39m.dropna = dropna\n\u001b[32m   1330\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1331\u001b[39m     grouper, exclusions, obj = \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1336\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1337\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1338\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1339\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1341\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib.no_default:\n\u001b[32m   1342\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping._passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper.groupings):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Miguel\\Desktop\\Miguelon\\GH\\Formacion_IA_DataScience_ML\\.venv\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:1043\u001b[39m, in \u001b[36mget_grouper\u001b[39m\u001b[34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[39m\n\u001b[32m   1041\u001b[39m         in_axis, level, gpr = \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[32m   1044\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr.key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1045\u001b[39m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[32m   1046\u001b[39m     exclusions.add(gpr.key)\n",
      "\u001b[31mKeyError\u001b[39m: 'nombre_producto'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Intentar importar matplotlib / seaborn; si faltan, desactivar trazado y avisar.\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.rcParams['figure.figsize'] = (10, 6)\n",
    "    _PLOTTING_AVAILABLE = True\n",
    "except Exception:\n",
    "    plt = None\n",
    "    sns = None\n",
    "    _PLOTTING_AVAILABLE = False\n",
    "    print(\"Aviso: matplotlib/seaborn no disponibles. Instalar con: python -m pip install matplotlib seaborn\")\n",
    "\n",
    "def _normalize_colname(col: str) -> str:\n",
    "    \"\"\"Normalize column name: strip, lowercase, replace spaces by underscore, remove non-word chars.\"\"\"\n",
    "    s = str(col).strip().lower()\n",
    "    s = re.sub(r'\\s+', '_', s)\n",
    "    s = re.sub(r'[^\\w_]', '', s)\n",
    "    return s\n",
    "\n",
    "def _normalize_columns_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Return DataFrame with normalized column names (non-destructive to data types).\"\"\"\n",
    "    mapping = {c: _normalize_colname(c) for c in df.columns}\n",
    "    return df.rename(columns=mapping)\n",
    "\n",
    "def _find_and_rename(df: pd.DataFrame, candidates: list, target: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    If any candidate exists in df columns, rename it to target.\n",
    "    Returns df (possibly modified).\n",
    "    \"\"\"\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            if c != target:\n",
    "                df = df.rename(columns={c: target})\n",
    "            return df\n",
    "    return df\n",
    "\n",
    "def cargar_datos(base_path: Path = Path(\".\")):\n",
    "    \"\"\"\n",
    "    Carga y valida los archivos de entrada (Excel o CSV).\n",
    "    Devuelve tuple: (df_clientes, df_detalle, df_productos, df_ventas) o (None, None, None, None) si falla.\n",
    "    \"\"\"\n",
    "    files = {\n",
    "        'clientes': base_path / 'clientes.xlsx',\n",
    "        'detalle': base_path / 'detalle_ventas.xlsx',\n",
    "        'productos': base_path / 'productos.xlsx',\n",
    "        'ventas': base_path / 'ventas.xlsx',\n",
    "    }\n",
    "\n",
    "    def _read(path: Path) -> pd.DataFrame:\n",
    "        if not path.exists():\n",
    "            raise FileNotFoundError(f\"No se encontr√≥: {path}\")\n",
    "        suffix = path.suffix.lower()\n",
    "        try:\n",
    "            if suffix in ('.xls', '.xlsx'):\n",
    "                return pd.read_excel(path, engine='openpyxl')\n",
    "            else:\n",
    "                try:\n",
    "                    return pd.read_csv(path, encoding='utf-8')\n",
    "                except UnicodeDecodeError:\n",
    "                    return pd.read_csv(path, encoding='latin-1')\n",
    "        except ValueError as e:\n",
    "            if 'openpyxl' in str(e).lower():\n",
    "                raise RuntimeError(\"Necesita instalar openpyxl: python -m pip install openpyxl\") from e\n",
    "            raise\n",
    "\n",
    "    try:\n",
    "        df_cli = _read(files['clientes'])\n",
    "        df_det = _read(files['detalle'])\n",
    "        df_prod = _read(files['productos'])\n",
    "        df_ven = _read(files['ventas'])\n",
    "\n",
    "        # Normalizar columnas (facilita fusiones y evita KeyError por nombres distintos)\n",
    "        df_cli = _normalize_columns_df(df_cli)\n",
    "        df_det = _normalize_columns_df(df_det)\n",
    "        df_prod = _normalize_columns_df(df_prod)\n",
    "        df_ven = _normalize_columns_df(df_ven)\n",
    "\n",
    "        print(\"‚úÖ Fase 1: Datos cargados y columnas normalizadas.\\n\")\n",
    "        datasets = {'Clientes': df_cli, 'Detalle': df_det, 'Productos': df_prod, 'Ventas': df_ven}\n",
    "        for nombre, df in datasets.items():\n",
    "            nulos = int(df.isnull().sum().sum())\n",
    "            estado = \"Sin nulos\" if nulos == 0 else f\"{nulos} nulos detectados\"\n",
    "            print(f\"{nombre}: {estado}\")\n",
    "\n",
    "        return df_cli, df_det, df_prod, df_ven\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"‚ùå Error cr√≠tico: {e}\")\n",
    "        return None, None, None, None\n",
    "    except RuntimeError as e:\n",
    "        print(f\"‚ùå Error de dependencias: {e}\")\n",
    "        return None, None, None, None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al leer archivos: {e}\")\n",
    "        return None, None, None, None\n",
    "\n",
    "def crear_dataset_maestro(df_ven: pd.DataFrame, df_det: pd.DataFrame, df_prod: pd.DataFrame, df_cli: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Realiza fusiones defensivas y normaliza nombres claves.\n",
    "    Devuelve DataFrame maestro con columnas esperadas:\n",
    "    id_venta, id_producto, id_cliente, nombre_producto, nombre_cliente, cantidad, importe, fecha, ...\n",
    "    \"\"\"\n",
    "    if df_ven is None:\n",
    "        raise ValueError(\"df_ven es None. Aseg√∫rate de haber cargado los datos.\")\n",
    "\n",
    "    # Normalizar y renombrar columnas clave usando candidatos comunes\n",
    "    id_venta_cands = ['id_venta','idventa','venta_id','ventaid']\n",
    "    id_producto_cands = ['id_producto','idproducto','producto_id','productoid']\n",
    "    id_cliente_cands = ['id_cliente','idcliente','cliente_id','clienteid']\n",
    "\n",
    "    nombre_producto_cands = ['nombre_producto','nombre_producto','nombre','producto','name','descripcion']\n",
    "    nombre_cliente_cands = ['nombre_cliente','nombre','cliente','name']\n",
    "\n",
    "    cantidad_cands = ['cantidad','qty','unidades','cantidad_vendida','units']\n",
    "    importe_cands = ['importe','monto','total','precio','valor']\n",
    "    fecha_cands = ['fecha','date','fecha_venta','fecha_venta']\n",
    "\n",
    "    # Aplicar renombrados en cada df (si se encuentra candidato)\n",
    "    for df, mapping in (\n",
    "        (df_det, {'id_venta': id_venta_cands, 'id_producto': id_producto_cands, 'cantidad': cantidad_cands, 'importe': importe_cands}),\n",
    "        (df_ven, {'id_venta': id_venta_cands, 'id_cliente': id_cliente_cands, 'fecha': fecha_cands, 'importe': importe_cands}),\n",
    "        (df_prod, {'id_producto': id_producto_cands, 'nombre_producto': nombre_producto_cands}),\n",
    "        (df_cli, {'id_cliente': id_cliente_cands, 'nombre_cliente': nombre_cliente_cands}),\n",
    "    ):\n",
    "        for target, cands in mapping.items():\n",
    "            df = _find_and_rename(df, cands, target)\n",
    "        # assign back for df_det/df_ven etc (we modified local variable)\n",
    "        if df is df_det:\n",
    "            df_det = df\n",
    "        elif df is df_ven:\n",
    "            df_ven = df\n",
    "        elif df is df_prod:\n",
    "            df_prod = df\n",
    "        elif df is df_cli:\n",
    "            df_cli = df\n",
    "\n",
    "    # Ahora verificar existencia de columnas clave y a√±adir fallbacks sensatos\n",
    "    if 'id_venta' not in df_det.columns:\n",
    "        raise KeyError(\"Columna 'id_venta' no encontrada en detalle de ventas.\")\n",
    "    if 'id_venta' not in df_ven.columns:\n",
    "        raise KeyError(\"Columna 'id_venta' no encontrada en ventas.\")\n",
    "\n",
    "    if 'id_producto' not in df_det.columns:\n",
    "        raise KeyError(\"Columna 'id_producto' no encontrada en detalle de ventas.\")\n",
    "    if 'id_producto' not in df_prod.columns:\n",
    "        # si no hay id_producto en productos, intentar crear desde √≠ndice\n",
    "        df_prod = df_prod.reset_index().rename(columns={'index': 'id_producto'})\n",
    "        if 'id_producto' not in df_prod.columns:\n",
    "            raise KeyError(\"Columna 'id_producto' no encontrada en productos y no se pudo inferir.\")\n",
    "\n",
    "    if 'id_cliente' not in df_ven.columns:\n",
    "        raise KeyError(\"Columna 'id_cliente' no encontrada en ventas.\")\n",
    "    if 'id_cliente' not in df_cli.columns:\n",
    "        # intentar crear fallback\n",
    "        df_cli = df_cli.reset_index().rename(columns={'index': 'id_cliente'})\n",
    "        if 'id_cliente' not in df_cli.columns:\n",
    "            raise KeyError(\"Columna 'id_cliente' no encontrada en clientes y no se pudo inferir.\")\n",
    "\n",
    "    # Asegurar existencia de columnas cantidad/importe\n",
    "    if 'cantidad' not in df_det.columns:\n",
    "        if 'cantidad' in df_det.columns:\n",
    "            pass\n",
    "        else:\n",
    "            # crear columna cantidad con 1 por defecto si no existe\n",
    "            df_det['cantidad'] = 1\n",
    "\n",
    "    if 'importe' not in df_det.columns and 'importe' not in df_ven.columns:\n",
    "        raise KeyError(\"No se encontr√≥ columna 'importe' en detalle ni en ventas.\")\n",
    "\n",
    "    # Ejecutar merges\n",
    "    master = pd.merge(df_ven, df_det, on='id_venta', how='inner', validate=\"1:m\")\n",
    "    master = pd.merge(master, df_prod, on='id_producto', how='left')\n",
    "    master = pd.merge(master, df_cli, on='id_cliente', how='left', suffixes=('', '_cliente'))\n",
    "\n",
    "    # Normalizar/asegurar tipo datetime en 'fecha'\n",
    "    if 'fecha' in master.columns:\n",
    "        master['fecha'] = pd.to_datetime(master['fecha'], errors='coerce')\n",
    "    else:\n",
    "        master['fecha'] = pd.NaT\n",
    "\n",
    "    print(f\"‚úÖ Fase 2 completada. Dimensiones del Dataset Maestro: {master.shape}\")\n",
    "    return master\n",
    "\n",
    "def analizar_productos(df: pd.DataFrame, top_n: int = 5):\n",
    "    \"\"\"\n",
    "    Muestra los productos m√°s vendidos por unidades e ingresos.\n",
    "    Detecta autom√°ticamente columna de nombre de producto si tiene otro nombre.\n",
    "    \"\"\"\n",
    "    # Buscar columna de nombre producto\n",
    "    name_col = next((c for c in ['nombre_producto','nombre','producto','name','descripcion'] if c in df.columns), None)\n",
    "    if name_col is None:\n",
    "        raise KeyError(\"No se encontr√≥ ninguna columna de nombre de producto en el dataset.\")\n",
    "    if name_col != 'nombre_producto':\n",
    "        df = df.rename(columns={name_col: 'nombre_producto'})\n",
    "\n",
    "    # Asegurar columnas num√©ricas\n",
    "    df['cantidad'] = pd.to_numeric(df.get('cantidad', 1), errors='coerce').fillna(1)\n",
    "    df['importe'] = pd.to_numeric(df.get('importe', 0), errors='coerce').fillna(0.0)\n",
    "\n",
    "    prod_stats = df.groupby('nombre_producto').agg({'cantidad': 'sum', 'importe': 'sum'})\n",
    "    top_cant = prod_stats.sort_values('cantidad', ascending=False).head(top_n)\n",
    "    top_ing = prod_stats.sort_values('importe', ascending=False).head(top_n)\n",
    "\n",
    "    print(\"\\nüìä Top por unidades:\\n\", top_cant)\n",
    "    print(\"\\nüìä Top por ingresos:\\n\", top_ing)\n",
    "\n",
    "    if _PLOTTING_AVAILABLE:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        sns.barplot(x=top_cant['cantidad'], y=top_cant.index, ax=axes[0], palette='viridis')\n",
    "        axes[0].set_title(f'Top {top_n} Productos m√°s Vendidos (Unidades)')\n",
    "        axes[0].set_xlabel('Unidades Vendidas')\n",
    "        axes[0].set_ylabel('')\n",
    "\n",
    "        sns.barplot(x=top_ing['importe'], y=top_ing.index, ax=axes[1], palette='magma')\n",
    "        axes[1].set_title(f'Top {top_n} Productos por Ingresos ($)')\n",
    "        axes[1].set_xlabel('Total Generado ($)')\n",
    "        axes[1].set_ylabel('')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Gr√°ficos omitidos: matplotlib/seaborn no disponibles.\")\n",
    "\n",
    "def analizar_tendencia_temporal(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Agrupa por mes-a√±o y muestra la tendencia de ingresos mensuales.\n",
    "    \"\"\"\n",
    "    if 'fecha' not in df.columns:\n",
    "        print(\"No hay columna 'fecha' para an√°lisis temporal.\")\n",
    "        return\n",
    "    df = df.copy()\n",
    "    df['fecha'] = pd.to_datetime(df['fecha'], errors='coerce')\n",
    "    df = df.dropna(subset=['fecha'])\n",
    "    if df.empty:\n",
    "        print(\"No hay fechas v√°lidas para an√°lisis temporal.\")\n",
    "        return\n",
    "\n",
    "    df['mes_a√±o'] = df['fecha'].dt.to_period('M')\n",
    "    df['importe'] = pd.to_numeric(df.get('importe', 0), errors='coerce').fillna(0.0)\n",
    "    ventas_mes = df.groupby('mes_a√±o')['importe'].sum()\n",
    "    print(\"\\nüìà Ventas por mes:\\n\", ventas_mes)\n",
    "\n",
    "    if _PLOTTING_AVAILABLE:\n",
    "        x_labels = ventas_mes.index.astype(str)\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.lineplot(x=x_labels, y=ventas_mes.values, marker='o', linewidth=3, color='#2ecc71')\n",
    "        plt.title('Tendencia de Ingresos Mensuales')\n",
    "        plt.ylabel('Ventas Totales ($)')\n",
    "        plt.xlabel('Mes')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        for x, y in zip(x_labels, ventas_mes.values):\n",
    "            plt.text(x, y, f\"${y:,.0f}\", ha='center', va='bottom', fontsize=9)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Gr√°ficos omitidos: matplotlib/seaborn no disponibles.\")\n",
    "\n",
    "def analizar_mejores_clientes(df: pd.DataFrame, top_n: int = 5):\n",
    "    \"\"\"\n",
    "    Identifica los clientes con mayor gasto acumulado.\n",
    "    \"\"\"\n",
    "    name_col = next((c for c in ['nombre_cliente','cliente','nombre','name'] if c in df.columns), None)\n",
    "    if name_col is None:\n",
    "        print(\"No se encontr√≥ columna de nombre de cliente. Se usar√° 'id_cliente' como etiqueta.\")\n",
    "        if 'id_cliente' not in df.columns:\n",
    "            raise KeyError(\"No hay columna para identificar clientes.\")\n",
    "        df['nombre_cliente'] = df['id_cliente'].astype(str)\n",
    "    else:\n",
    "        if name_col != 'nombre_cliente':\n",
    "            df = df.rename(columns={name_col: 'nombre_cliente'})\n",
    "\n",
    "    df['importe'] = pd.to_numeric(df.get('importe', 0), errors='coerce').fillna(0.0)\n",
    "    top_clientes = df.groupby('nombre_cliente')['importe'].sum().sort_values(ascending=False).head(top_n)\n",
    "    print(\"\\nüë• Top clientes por gasto:\\n\", top_clientes)\n",
    "\n",
    "    if _PLOTTING_AVAILABLE:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        sns.barplot(x=top_clientes.values, y=top_clientes.index, palette='coolwarm')\n",
    "        plt.title(f'Top {top_n} Clientes con Mayor Volumen de Compra')\n",
    "        plt.xlabel('Gasto Total Acumulado ($)')\n",
    "        plt.ylabel('Cliente')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Gr√°ficos omitidos: matplotlib/seaborn no disponibles.\")\n",
    "\n",
    "# --- EJECUCI√ìN PRINCIPAL ---\n",
    "def main():\n",
    "    base_path = Path(\".\")\n",
    "    df_clientes, df_detalle, df_productos, df_ventas = cargar_datos(base_path)\n",
    "\n",
    "    if df_clientes is None:\n",
    "        print(\"Finalizando: no se cargaron datos.\")\n",
    "        return\n",
    "\n",
    "    df_maestro = crear_dataset_maestro(df_ventas, df_detalle, df_productos, df_clientes)\n",
    "    analizar_productos(df_maestro)\n",
    "    analizar_tendencia_temporal(df_maestro)\n",
    "    analizar_mejores_clientes(df_maestro)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "```# filepath: c:\\Users\\Miguel\\Desktop\\Miguelon\\GH\\Formacion_IA_DataScience_ML\\Sprint-2\\Data\\Tienda_Aurelion.ipynb\n",
    "import sys\n",
    "from pathlib"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
