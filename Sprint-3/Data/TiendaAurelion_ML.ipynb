{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11c56ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ SPRINT 3: Iniciando carga inteligente de datos...\n",
      "   ‚ùå ERROR CR√çTICO: No se encontr√≥ el archivo para 'clientes'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# --- CONFIGURACI√ìN VISUAL (PROFESIONAL) ---\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# --- FUNCI√ìN DE B√öSQUEDA INTELIGENTE ---\n",
    "def buscar_archivo_por_palabra_clave(palabra_clave, extension=\".csv\"):\n",
    "    \"\"\"\n",
    "    Busca en la carpeta actual cualquier archivo que contenga \n",
    "    la 'palabra_clave' en su nombre (ej: 'clientes').\n",
    "    \"\"\"\n",
    "    directorio_actual = os.getcwd()\n",
    "    archivos_en_carpeta = os.listdir(directorio_actual)\n",
    "    \n",
    "    # Filtramos archivos que contengan la palabra clave y terminen en .csv\n",
    "    candidatos = [f for f in archivos_en_carpeta if palabra_clave in f and f.endswith(extension)]\n",
    "    \n",
    "    if candidatos:\n",
    "        # Retornamos el primero que encuentre (el m√°s probable)\n",
    "        print(f\"   ‚úÖ Archivo encontrado para '{palabra_clave}': {candidatos[0]}\")\n",
    "        return candidates[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# --- CARGA Y PROCESAMIENTO (ETL) ---\n",
    "def cargar_datos_sprint_3():\n",
    "    print(\"üöÄ SPRINT 3: Iniciando carga de datos...\")\n",
    "    print(f\"üìÇ Buscando en carpeta: {os.getcwd()}\\n\")\n",
    "    \n",
    "    # Diccionario para guardar los dataframes\n",
    "    dfs = {}\n",
    "    palabras_clave = ['clientes', 'detalle', 'productos', 'ventas']\n",
    "    \n",
    "    try:\n",
    "        for clave in palabras_clave:\n",
    "            archivo = buscar_archivo_por_palabra_clave(clave)\n",
    "            \n",
    "            if archivo:\n",
    "                # Usamos 'latin-1' para corregir errores de tildes/√±\n",
    "                dfs[clave] = pd.read_csv(archivo, encoding='latin-1')\n",
    "            else:\n",
    "                # Error espec√≠fico si falta un archivo\n",
    "                raise FileNotFoundError(f\"‚ùå No se encontr√≥ ning√∫n archivo que contenga la palabra '{clave}' en esta carpeta.\")\n",
    "\n",
    "        # Asignamos variables\n",
    "        df_cli = dfs['clientes']\n",
    "        df_det = dfs['detalle'] # Busca 'detalle' (coincide con 'detalle_ventas...')\n",
    "        df_prod = dfs['productos']\n",
    "        df_ven = dfs['ventas']\n",
    "\n",
    "        # Conversi√≥n de fechas\n",
    "        df_ven['fecha'] = pd.to_datetime(df_ven['fecha'])\n",
    "        \n",
    "        print(\"\\nüîÑ Fusionando tablas (Data Merging)...\")\n",
    "        \n",
    "        # 1. Unir Detalle con Ventas (Inner Join)\n",
    "        df_master = pd.merge(df_det, df_ven, on='id_venta', how='inner')\n",
    "        \n",
    "        # 2. Agregar informaci√≥n de Productos (Left Join)\n",
    "        # Usamos suffixes para que 'nombre_producto' no choque con columnas duplicadas\n",
    "        df_master = pd.merge(df_master, df_prod, on='id_producto', how='left', suffixes=('', '_prod_dup'))\n",
    "        \n",
    "        # 3. Agregar informaci√≥n de Clientes (Left Join)\n",
    "        df_master = pd.merge(df_master, df_cli, on='id_cliente', how='left', suffixes=('', '_cli_dup'))\n",
    "        \n",
    "        print(f\"‚úÖ Dataset Maestro generado con √©xito: {df_master.shape[0]} registros procesados.\")\n",
    "        return df_master\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚õî ERROR CR√çTICO DE EJECUCI√ìN: {e}\")\n",
    "        print(\"üí° TIP: Verifica que tus 4 archivos .csv est√©n en la misma carpeta que este Notebook.\")\n",
    "        return None\n",
    "\n",
    "# --- AN√ÅLISIS SPRINT 3 ---\n",
    "\n",
    "def analisis_categorias_rentables(df):\n",
    "    \"\"\" Tarea 1: ¬øQu√© categor√≠a genera m√°s ingresos? \"\"\"\n",
    "    print(\"\\nüì¶ Visualizando: Rentabilidad por Categor√≠a...\")\n",
    "    \n",
    "    # Agrupamos por categor√≠a y sumamos importe\n",
    "    data = df.groupby('categoria')['importe'].sum().sort_values(ascending=False)\n",
    "    \n",
    "    plt.figure()\n",
    "    ax = sns.barplot(x=data.index, y=data.values, palette='viridis', hue=data.index, legend=False)\n",
    "    \n",
    "    plt.title('Ingresos Totales por Categor√≠a', fontweight='bold')\n",
    "    plt.ylabel('Facturaci√≥n ($)')\n",
    "    plt.xlabel('Categor√≠a')\n",
    "    \n",
    "    # Formato de dinero en el eje Y\n",
    "    ax.yaxis.set_major_formatter('${x:,.0f}')\n",
    "    plt.show()\n",
    "\n",
    "def analisis_medios_pago(df):\n",
    "    \"\"\" Tarea 2: Preferencia de Medios de Pago (Donut Chart) \"\"\"\n",
    "    print(\"\\nüí≥ Visualizando: Preferencias de Pago...\")\n",
    "    \n",
    "    # IMPORTANTE: Eliminamos duplicados de id_venta para contar transacciones √∫nicas, no productos\n",
    "    transacciones_unicas = df.drop_duplicates(subset='id_venta')\n",
    "    data = transacciones_unicas['medio_pago'].value_counts()\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    # Colores suaves\n",
    "    colors = sns.color_palette('pastel')[0:5]\n",
    "    \n",
    "    plt.pie(data, labels=data.index, autopct='%1.1f%%', startangle=140, colors=colors, pctdistance=0.85)\n",
    "    \n",
    "    # C√≠rculo blanco para efecto Donut\n",
    "    centre_circle = plt.Circle((0,0),0.70,fc='white')\n",
    "    fig = plt.gcf()\n",
    "    fig.gca().add_artist(centre_circle)\n",
    "    \n",
    "    plt.title('Distribuci√≥n de Medios de Pago', fontweight='bold')\n",
    "    plt.show()\n",
    "\n",
    "def analisis_geografico(df):\n",
    "    \"\"\" Tarea 3: Ventas por Ciudad \"\"\"\n",
    "    print(\"\\nüìç Visualizando: Desempe√±o Geogr√°fico...\")\n",
    "    \n",
    "    data = df.groupby('ciudad')['importe'].sum().sort_values(ascending=False)\n",
    "    \n",
    "    plt.figure()\n",
    "    sns.barplot(x=data.values, y=data.index, palette='coolwarm', hue=data.index, legend=False)\n",
    "    \n",
    "    plt.title('Ranking de Ventas por Ciudad', fontweight='bold')\n",
    "    plt.xlabel('Total Vendido ($)')\n",
    "    plt.ylabel('')\n",
    "    plt.show()\n",
    "\n",
    "# --- EJECUCI√ìN PRINCIPAL ---\n",
    "if __name__ == \"__main__\":\n",
    "    df_sprint3 = cargar_datos_sprint_3()\n",
    "    \n",
    "    if df_sprint3 is not None:\n",
    "        analisis_categorias_rentables(df_sprint3)\n",
    "        analisis_medios_pago(df_sprint3)\n",
    "        analisis_geografico(df_sprint3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
